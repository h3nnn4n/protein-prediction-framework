{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment information:\n",
    "- One million function evaluations\n",
    "- **sade_remc**: is the best method from HM, but with more evals\n",
    "- **sade_mc_final**: is sade + MC + ffi9 + rmsd crowding + spicker + hooke jeeves on cluster centroids\n",
    "- **sade_remc_final**: is the same as above, but REMC instead of MC\n",
    "- **sade_mc_ffi9_02**: is HM method + forced fragment insertion of size 2 with 0.02 chance of happening per individal per generation\n",
    "- **sade_remc_ffi9_02**: same as above but with REMC instead of MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import string\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "\n",
    "import utils\n",
    "import data_utils\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/home/h3nnn4n/progs/de_supimpa/tools/notebooks/analysis'\n",
    "base_path = '/home/h3nnn4n/progs/de_supimpa/src'\n",
    "\n",
    "\n",
    "def reset_path():\n",
    "    os.chdir(base_path)\n",
    "    \n",
    "    \n",
    "def reset_to_root_path():\n",
    "    os.chdir(root_path)\n",
    "\n",
    "    \n",
    "reset_to_root_path()\n",
    "reset_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = [\n",
    "    'de_experiment_final',\n",
    "    'de_sade_remc',\n",
    "    'de_rosetta',\n",
    "    'de_ffi',\n",
    "    'de_experiment_final_8_prot',\n",
    "    'de_final_1rop_1wqc_1lwy',\n",
    "    'de_rosetta_all_prots',\n",
    "    'de_other_experiments_all_prots',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Parsing     500 repack.dat files\n",
      "INFO: Parsing     448 repack.dat files\n",
      "INFO: Parsing     500 repack.dat files\n",
      "INFO: Parsing     430 repack.dat files\n",
      "INFO: Parsing     501 repack.dat files\n",
      "INFO: Parsing     438 repack.dat files\n",
      "INFO: Parsing     500 repack.dat files\n",
      "INFO: Parsing     496 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing     732 repack.dat files\n",
      "INFO: Parsing     663 repack.dat files\n",
      "INFO: Parsing     740 repack.dat files\n",
      "INFO: Parsing     751 repack.dat files\n",
      "INFO: Parsing     730 repack.dat files\n",
      "INFO: Parsing     625 repack.dat files\n",
      "INFO: Parsing     727 repack.dat files\n",
      "INFO: Parsing     715 repack.dat files\n",
      "INFO: Parsing     200 repack.dat files\n",
      "INFO: Parsing     181 repack.dat files\n",
      "INFO: Parsing     753 repack.dat files\n",
      "INFO: Parsing     654 repack.dat files\n",
      "INFO: Parsing     190 repack.dat files\n",
      "INFO: Parsing     152 repack.dat files\n",
      "INFO: Parsing     190 repack.dat files\n",
      "INFO: Parsing     171 repack.dat files\n",
      "INFO: Parsing     752 repack.dat files\n",
      "INFO: Parsing     706 repack.dat files\n",
      "INFO: Parsing     761 repack.dat files\n",
      "INFO: Parsing     701 repack.dat files\n",
      "INFO: Parsing     200 repack.dat files\n",
      "INFO: Parsing     190 repack.dat files\n",
      "INFO: Parsing     730 repack.dat files\n",
      "INFO: Parsing     674 repack.dat files\n",
      "INFO: Parsing     408 repack.dat files\n",
      "INFO: Parsing     484 repack.dat files\n",
      "INFO: Parsing     487 repack.dat files\n",
      "INFO: Parsing     456 repack.dat files\n",
      "INFO: Parsing     502 repack.dat files\n",
      "INFO: Parsing     504 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      47 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "def list_contains_substring(container, string):\n",
    "    return any(map(lambda x: x in string, container))\n",
    "\n",
    "\n",
    "def find_experiment_folder(run):\n",
    "    dirs = [f for f in os.listdir() if os.path.isdir(f)]\n",
    "    exp_folder = [f for f in dirs if list_contains_substring(runs, f)]\n",
    "    \n",
    "    if len(exp_folder) > 1:\n",
    "        raise Exception('Found more than one experiment folder. Aborting\\n%s' % exp_folder)\n",
    "        \n",
    "    return exp_folder[0]\n",
    "\n",
    "\n",
    "def load_repack_data():\n",
    "    os.chdir('repack')\n",
    "    d = utils.get_by_best_rmsd()\n",
    "    os.chdir('..')\n",
    "    \n",
    "    return d\n",
    "\n",
    "\n",
    "def load_hooke_jeeves_data():\n",
    "    os.chdir('hooke-jeeves')\n",
    "    d = []\n",
    "    wanted_data = ['hooke_time', 'spent_evals']\n",
    "    \n",
    "    for datafile in os.listdir():\n",
    "        with open(datafile, 'rt') as f:\n",
    "            new_data = {}\n",
    "            for line in f.readlines():\n",
    "                tokens = re.sub(' {2,}', ' ', line.strip()).split(' ')\n",
    "\n",
    "                has_data = any([wanted == tokens[0][:-1] for wanted in wanted_data])\n",
    "                if has_data:\n",
    "                    new_data[tokens[0][:-1]] = float(tokens[1])\n",
    "                    \n",
    "            d.append(new_data)\n",
    "            \n",
    "    os.chdir('..')\n",
    "    \n",
    "    return d\n",
    "\n",
    "\n",
    "def load_stats_data():\n",
    "    os.chdir('stats')\n",
    "    d = []\n",
    "    \n",
    "    for datafile in os.listdir():\n",
    "        with open(datafile, 'rt') as f:\n",
    "            new_data = {}\n",
    "            for line in f.readlines():\n",
    "                tokens = re.sub(' {2,}', ' ', line.strip()).split(' ')\n",
    "\n",
    "                new_data['evals'] = float(tokens[0])\n",
    "                new_data['time'] = float(tokens[8])\n",
    "                    \n",
    "            d.append(new_data)\n",
    "            \n",
    "    os.chdir('..')\n",
    "    \n",
    "    return d\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    reset_path()\n",
    "    \n",
    "    data = {}\n",
    "    data_hooke = {}\n",
    "    data_stats = {}\n",
    "    \n",
    "    for run in runs:\n",
    "        os.chdir(run)\n",
    "        \n",
    "        exp_folder = find_experiment_folder(run)\n",
    "        os.chdir(exp_folder)\n",
    "        \n",
    "        protein_folders = [f for f in os.listdir() if len(f) == 4 and os.path.isdir(f)]\n",
    "        \n",
    "        for pf in protein_folders:\n",
    "            os.chdir(pf)\n",
    "            if pf not in data.keys():\n",
    "                data[pf] = {}\n",
    "                data_hooke[pf] = {}\n",
    "                data_stats[pf] = {}\n",
    "            \n",
    "            for exp in os.listdir():\n",
    "                os.chdir(exp)\n",
    "                    \n",
    "                data[pf][exp] = load_repack_data()\n",
    "                data_hooke[pf][exp] = load_hooke_jeeves_data()\n",
    "                data_stats[pf][exp] = load_stats_data()\n",
    "                \n",
    "                os.chdir('..')\n",
    "            \n",
    "            os.chdir('..')\n",
    "        \n",
    "        os.chdir('..')\n",
    "        os.chdir('..')\n",
    "        \n",
    "    return data, data_hooke, data_stats\n",
    "    \n",
    "    \n",
    "data, data_hooke, data_stats = load_data()\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric(data_, protein, experiment, metric):\n",
    "    data_source = data_[protein][experiment]\n",
    "    data_metric = [d[metric] for d in data_source]\n",
    "    \n",
    "    return data_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_blacklist = ['1ab1', '1dfn', '2p5k', '2pmr', '3v1a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1acw & $381.8566$ & $76.8664$ \\\\ \\hline\n",
      "1ail & $1141.1461$ & $142.2935$ \\\\ \\hline\n",
      "1crn & $721.0492$ & $118.6126$ \\\\ \\hline\n",
      "1enh & $763.7677$ & $86.2599$ \\\\ \\hline\n",
      "1l2y & $252.8980$ & $19.1262$ \\\\ \\hline\n",
      "1rop & $963.2695$ & $124.7610$ \\\\ \\hline\n",
      "1utg & $1010.0412$ & $142.8927$ \\\\ \\hline\n",
      "1wqc & $341.4484$ & $35.1510$ \\\\ \\hline\n",
      "1zdd & $462.3010$ & $127.2581$ \\\\ \\hline\n",
      "2mr9 & $702.5817$ & $95.6492$ \\\\ \\hline\n",
      "\n",
      "1acw & $397.3399$ & $39.2449$ \\\\ \\hline\n",
      "1ail & $1127.3899$ & $139.9729$ \\\\ \\hline\n",
      "1crn & $696.0591$ & $78.4302$ \\\\ \\hline\n",
      "1enh & $783.4028$ & $95.5297$ \\\\ \\hline\n",
      "1l2y & $252.7463$ & $18.8516$ \\\\ \\hline\n",
      "1rop & $940.5557$ & $203.5212$ \\\\ \\hline\n",
      "1utg & $1018.6922$ & $193.5863$ \\\\ \\hline\n",
      "1wqc & $346.3862$ & $36.6248$ \\\\ \\hline\n",
      "1zdd & $483.3383$ & $50.8998$ \\\\ \\hline\n",
      "2mr9 & $695.9580$ & $189.4521$ \\\\ \\hline\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def spent_time_table(wanted_experiments=['sade_mc_final', 'sade_remc_final']):\n",
    "    for experiment in wanted_experiments:\n",
    "        for protein in sorted(list(data.keys())):\n",
    "            if protein in protein_blacklist:\n",
    "                continue\n",
    "                \n",
    "            if experiment not in wanted_experiments:\n",
    "                continue\n",
    "                                \n",
    "            d1 = get_metric(data, protein, experiment, 'repack_time')\n",
    "            d2 = get_metric(data_hooke, protein, experiment, 'hooke_time')\n",
    "            d3 = get_metric(data_stats, protein, experiment, 'time')\n",
    "            \n",
    "            d_mean = np.mean(d1) + np.mean(d2) * 10 + np.mean(d3)\n",
    "            d_std = np.std(d1) + np.std(d2) * 10 + np.std(d3)\n",
    "\n",
    "            print(\"%s & $%0.4f$ & $%0.4f$ \\\\\\\\ \\\\hline\" % (protein, d_mean, d_std))\n",
    "        print()\n",
    "    \n",
    "spent_time_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1acw & $65764.0000$ & $19894.6690$ & $9323.3251$ \\\\ \\hline\n",
      "1ail & $63898.0000$ & $23215.9890$ & $12096.6411$ \\\\ \\hline\n",
      "1crn & $85706.0000$ & $23704.9947$ & $11297.4331$ \\\\ \\hline\n",
      "1enh & $63347.0000$ & $21141.6667$ & $11922.8046$ \\\\ \\hline\n",
      "1l2y & $41279.0000$ & $16022.7659$ & $7145.3393$ \\\\ \\hline\n",
      "1rop & $74935.0000$ & $21008.9153$ & $11595.2773$ \\\\ \\hline\n",
      "1utg & $82554.0000$ & $23257.8303$ & $13708.3805$ \\\\ \\hline\n",
      "1wqc & $50201.0000$ & $18342.0987$ & $8163.8972$ \\\\ \\hline\n",
      "1zdd & $56218.0000$ & $21848.3618$ & $10229.3850$ \\\\ \\hline\n",
      "2mr9 & $67762.0000$ & $22260.8176$ & $11415.6200$ \\\\ \\hline\n",
      "\n",
      "1acw & $57595.0000$ & $19818.5598$ & $8795.8194$ \\\\ \\hline\n",
      "1ail & $66802.0000$ & $24927.3000$ & $11983.8881$ \\\\ \\hline\n",
      "1crn & $59047.0000$ & $22657.6200$ & $10469.2788$ \\\\ \\hline\n",
      "1enh & $83720.0000$ & $24419.4684$ & $13052.6594$ \\\\ \\hline\n",
      "1l2y & $37358.0000$ & $15968.0817$ & $6859.0816$ \\\\ \\hline\n",
      "1rop & $64987.0000$ & $23404.5686$ & $11476.0593$ \\\\ \\hline\n",
      "1utg & $446525.0000$ & $26221.2802$ & $20265.7668$ \\\\ \\hline\n",
      "1wqc & $53722.0000$ & $18962.6016$ & $8634.9350$ \\\\ \\hline\n",
      "1zdd & $60950.0000$ & $21914.6842$ & $9503.5863$ \\\\ \\hline\n",
      "2mr9 & $815945.0000$ & $24356.2630$ & $31478.7399$ \\\\ \\hline\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def spent_evals_table(wanted_experiments=['sade_mc_final', 'sade_remc_final']):\n",
    "    base = 100000\n",
    "\n",
    "    for experiment in wanted_experiments:\n",
    "        for protein in sorted(list(data.keys())):\n",
    "            if protein in protein_blacklist:\n",
    "                continue\n",
    "                \n",
    "            if experiment not in wanted_experiments:\n",
    "                continue\n",
    "                              \n",
    "            d = get_metric(data_hooke, protein, experiment, 'spent_evals')\n",
    "            \n",
    "            print(\"%s & $%0.4f$ & $%0.4f$ & $%0.4f$ \\\\\\\\ \\\\hline\" % (protein, max(d), np.mean(d), np.std(d)))\n",
    "        print()\n",
    "    \n",
    "spent_evals_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
