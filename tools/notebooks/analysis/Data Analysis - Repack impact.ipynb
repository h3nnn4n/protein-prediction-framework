{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment information:\n",
    "- One million function evaluations\n",
    "- **sade_remc**: is the best method from HM, but with more evals\n",
    "- **sade_mc_final**: is sade + MC + ffi9 + rmsd crowding + spicker + hooke jeeves on cluster centroids\n",
    "- **sade_remc_final**: is the same as above, but REMC instead of MC\n",
    "- **sade_mc_ffi9_02**: is HM method + forced fragment insertion of size 2 with 0.02 chance of happening per individal per generation\n",
    "- **sade_remc_ffi9_02**: same as above but with REMC instead of MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import string\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "\n",
    "import utils\n",
    "import data_utils\n",
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/home/h3nnn4n/progs/de_supimpa/tools/notebooks/analysis'\n",
    "base_path = '/home/h3nnn4n/progs/de_supimpa/src'\n",
    "\n",
    "\n",
    "def reset_path():\n",
    "    os.chdir(base_path)\n",
    "    \n",
    "    \n",
    "def reset_to_root_path():\n",
    "    os.chdir(root_path)\n",
    "\n",
    "    \n",
    "reset_to_root_path()\n",
    "reset_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = [\n",
    "    'de_experiment_final',\n",
    "    'de_sade_remc',\n",
    "    'de_rosetta',\n",
    "    'de_ffi',\n",
    "    'de_experiment_final_8_prot',\n",
    "    'de_final_1rop_1wqc_1lwy',\n",
    "    'de_rosetta_all_prots',\n",
    "    'de_other_experiments_all_prots',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_blacklist = ['1ab1', '1dfn', '2p5k', '2pmr', '3v1a']\n",
    "\n",
    "def remove_blacklisted_proteins(alldata, protein_blacklist):\n",
    "    proteins_before = list(alldata.keys())\n",
    "\n",
    "    for protein in protein_blacklist:\n",
    "        alldata.pop(protein.lower(), False)\n",
    "\n",
    "    proteins_after = list(alldata.keys())\n",
    "\n",
    "    print('removed %d proteins. Blacklist had %d' % (\n",
    "        len(proteins_before) - len(proteins_after),\n",
    "        len(protein_blacklist)\n",
    "    ))\n",
    "\n",
    "\n",
    "def remove_not_common_methods(alldata):\n",
    "    first_key = list(alldata.keys())[0]\n",
    "    methods = set(alldata[first_key].keys())\n",
    "\n",
    "    for _, protein_methods in alldata.items():\n",
    "        methods_ = set(protein_methods.keys())\n",
    "        methods = methods & methods_\n",
    "\n",
    "    proteins = list(alldata.keys())\n",
    "    for protein in proteins:\n",
    "        protein_methods = list(alldata[protein].keys())\n",
    "\n",
    "        for protein_method in protein_methods:\n",
    "            if protein_method not in methods:\n",
    "                print('[WARN] removing %s from %s' % (protein_method, protein))\n",
    "                alldata[protein].pop(protein_method, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Parsing     500 repack.dat files\n",
      "INFO: Parsing     500 repack.dat files\n",
      "INFO: Parsing     500 repack.dat files\n",
      "INFO: Parsing     500 repack.dat files\n",
      "INFO: Parsing     448 repack.dat files\n",
      "INFO: Parsing     448 repack.dat files\n",
      "INFO: Parsing     448 repack.dat files\n",
      "INFO: Parsing     448 repack.dat files\n",
      "INFO: Parsing     500 repack.dat files\n",
      "INFO: Parsing     500 repack.dat files\n",
      "INFO: Parsing     500 repack.dat files\n",
      "INFO: Parsing     500 repack.dat files\n",
      "INFO: Parsing     430 repack.dat files\n",
      "INFO: Parsing     430 repack.dat files\n",
      "INFO: Parsing     430 repack.dat files\n",
      "INFO: Parsing     430 repack.dat files\n",
      "INFO: Parsing     501 repack.dat files\n",
      "INFO: Parsing     501 repack.dat files\n",
      "INFO: Parsing     501 repack.dat files\n",
      "INFO: Parsing     501 repack.dat files\n",
      "INFO: Parsing     438 repack.dat files\n",
      "INFO: Parsing     438 repack.dat files\n",
      "INFO: Parsing     438 repack.dat files\n",
      "INFO: Parsing     438 repack.dat files\n",
      "INFO: Parsing     500 repack.dat files\n",
      "INFO: Parsing     500 repack.dat files\n",
      "INFO: Parsing     500 repack.dat files\n",
      "INFO: Parsing     500 repack.dat files\n",
      "INFO: Parsing     496 repack.dat files\n",
      "INFO: Parsing     496 repack.dat files\n",
      "INFO: Parsing     496 repack.dat files\n",
      "INFO: Parsing     496 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing     730 repack.dat files\n",
      "INFO: Parsing     730 repack.dat files\n",
      "INFO: Parsing     730 repack.dat files\n",
      "INFO: Parsing     730 repack.dat files\n",
      "INFO: Parsing     625 repack.dat files\n",
      "INFO: Parsing     625 repack.dat files\n",
      "INFO: Parsing     625 repack.dat files\n",
      "INFO: Parsing     625 repack.dat files\n",
      "INFO: Parsing     200 repack.dat files\n",
      "INFO: Parsing     200 repack.dat files\n",
      "INFO: Parsing     200 repack.dat files\n",
      "INFO: Parsing     200 repack.dat files\n",
      "INFO: Parsing     181 repack.dat files\n",
      "INFO: Parsing     181 repack.dat files\n",
      "INFO: Parsing     181 repack.dat files\n",
      "INFO: Parsing     181 repack.dat files\n",
      "INFO: Parsing     753 repack.dat files\n",
      "INFO: Parsing     753 repack.dat files\n",
      "INFO: Parsing     753 repack.dat files\n",
      "INFO: Parsing     753 repack.dat files\n",
      "INFO: Parsing     654 repack.dat files\n",
      "INFO: Parsing     654 repack.dat files\n",
      "INFO: Parsing     654 repack.dat files\n",
      "INFO: Parsing     654 repack.dat files\n",
      "INFO: Parsing     190 repack.dat files\n",
      "INFO: Parsing     190 repack.dat files\n",
      "INFO: Parsing     190 repack.dat files\n",
      "INFO: Parsing     190 repack.dat files\n",
      "INFO: Parsing     152 repack.dat files\n",
      "INFO: Parsing     152 repack.dat files\n",
      "INFO: Parsing     152 repack.dat files\n",
      "INFO: Parsing     152 repack.dat files\n",
      "INFO: Parsing     190 repack.dat files\n",
      "INFO: Parsing     190 repack.dat files\n",
      "INFO: Parsing     190 repack.dat files\n",
      "INFO: Parsing     190 repack.dat files\n",
      "INFO: Parsing     171 repack.dat files\n",
      "INFO: Parsing     171 repack.dat files\n",
      "INFO: Parsing     171 repack.dat files\n",
      "INFO: Parsing     171 repack.dat files\n",
      "INFO: Parsing     761 repack.dat files\n",
      "INFO: Parsing     761 repack.dat files\n",
      "INFO: Parsing     761 repack.dat files\n",
      "INFO: Parsing     761 repack.dat files\n",
      "INFO: Parsing     701 repack.dat files\n",
      "INFO: Parsing     701 repack.dat files\n",
      "INFO: Parsing     701 repack.dat files\n",
      "INFO: Parsing     701 repack.dat files\n",
      "INFO: Parsing     200 repack.dat files\n",
      "INFO: Parsing     200 repack.dat files\n",
      "INFO: Parsing     200 repack.dat files\n",
      "INFO: Parsing     200 repack.dat files\n",
      "INFO: Parsing     190 repack.dat files\n",
      "INFO: Parsing     190 repack.dat files\n",
      "INFO: Parsing     190 repack.dat files\n",
      "INFO: Parsing     190 repack.dat files\n",
      "INFO: Parsing     408 repack.dat files\n",
      "INFO: Parsing     408 repack.dat files\n",
      "INFO: Parsing     408 repack.dat files\n",
      "INFO: Parsing     408 repack.dat files\n",
      "INFO: Parsing     484 repack.dat files\n",
      "INFO: Parsing     484 repack.dat files\n",
      "INFO: Parsing     484 repack.dat files\n",
      "INFO: Parsing     484 repack.dat files\n",
      "INFO: Parsing     487 repack.dat files\n",
      "INFO: Parsing     487 repack.dat files\n",
      "INFO: Parsing     487 repack.dat files\n",
      "INFO: Parsing     487 repack.dat files\n",
      "INFO: Parsing     456 repack.dat files\n",
      "INFO: Parsing     456 repack.dat files\n",
      "INFO: Parsing     456 repack.dat files\n",
      "INFO: Parsing     456 repack.dat files\n",
      "INFO: Parsing     502 repack.dat files\n",
      "INFO: Parsing     502 repack.dat files\n",
      "INFO: Parsing     502 repack.dat files\n",
      "INFO: Parsing     502 repack.dat files\n",
      "INFO: Parsing     504 repack.dat files\n",
      "INFO: Parsing     504 repack.dat files\n",
      "INFO: Parsing     504 repack.dat files\n",
      "INFO: Parsing     504 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      47 repack.dat files\n",
      "INFO: Parsing      47 repack.dat files\n",
      "INFO: Parsing      47 repack.dat files\n",
      "INFO: Parsing      47 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      49 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "INFO: Parsing      50 repack.dat files\n",
      "[WARN] removing sade_de_remc from 1rop\n",
      "[WARN] removing sade_mc from 1rop\n",
      "[WARN] removing sade_de_mc from 1rop\n",
      "[WARN] removing sade_de_remc from 2mr9\n",
      "[WARN] removing sade_mc from 2mr9\n",
      "[WARN] removing sade_de_mc from 2mr9\n",
      "[WARN] removing sade_de_remc from 1wqc\n",
      "[WARN] removing sade_mc from 1wqc\n",
      "[WARN] removing sade_de_mc from 1wqc\n",
      "[WARN] removing sade_de_remc from 1acw\n",
      "[WARN] removing sade_mc from 1acw\n",
      "[WARN] removing sade_de_mc from 1acw\n",
      "[WARN] removing sade_de_remc from 1utg\n",
      "[WARN] removing sade_mc from 1utg\n",
      "[WARN] removing sade_de_mc from 1utg\n",
      "[WARN] removing sade_de_remc from 1l2y\n",
      "[WARN] removing sade_mc from 1l2y\n",
      "[WARN] removing sade_de_mc from 1l2y\n",
      "[WARN] removing sade_de_remc from 1rop\n",
      "[WARN] removing sade_mc from 1rop\n",
      "[WARN] removing sade_de_mc from 1rop\n",
      "[WARN] removing sade_de_remc from 2mr9\n",
      "[WARN] removing sade_mc from 2mr9\n",
      "[WARN] removing sade_de_mc from 2mr9\n",
      "[WARN] removing sade_de_remc from 1wqc\n",
      "[WARN] removing sade_mc from 1wqc\n",
      "[WARN] removing sade_de_mc from 1wqc\n",
      "[WARN] removing sade_de_remc from 1acw\n",
      "[WARN] removing sade_mc from 1acw\n",
      "[WARN] removing sade_de_mc from 1acw\n",
      "[WARN] removing sade_de_remc from 1utg\n",
      "[WARN] removing sade_mc from 1utg\n",
      "[WARN] removing sade_de_mc from 1utg\n",
      "[WARN] removing sade_de_remc from 1l2y\n",
      "[WARN] removing sade_mc from 1l2y\n",
      "[WARN] removing sade_de_mc from 1l2y\n",
      "[WARN] removing sade_de_remc from 1rop\n",
      "[WARN] removing sade_mc from 1rop\n",
      "[WARN] removing sade_de_mc from 1rop\n",
      "[WARN] removing sade_de_remc from 2mr9\n",
      "[WARN] removing sade_mc from 2mr9\n",
      "[WARN] removing sade_de_mc from 2mr9\n",
      "[WARN] removing sade_de_remc from 1wqc\n",
      "[WARN] removing sade_mc from 1wqc\n",
      "[WARN] removing sade_de_mc from 1wqc\n",
      "[WARN] removing sade_de_remc from 1acw\n",
      "[WARN] removing sade_mc from 1acw\n",
      "[WARN] removing sade_de_mc from 1acw\n",
      "[WARN] removing sade_de_remc from 1utg\n",
      "[WARN] removing sade_mc from 1utg\n",
      "[WARN] removing sade_de_mc from 1utg\n",
      "[WARN] removing sade_de_remc from 1l2y\n",
      "[WARN] removing sade_mc from 1l2y\n",
      "[WARN] removing sade_de_mc from 1l2y\n",
      "[WARN] removing sade_de_remc from 1rop\n",
      "[WARN] removing sade_mc from 1rop\n",
      "[WARN] removing sade_de_mc from 1rop\n",
      "[WARN] removing sade_de_remc from 2mr9\n",
      "[WARN] removing sade_mc from 2mr9\n",
      "[WARN] removing sade_de_mc from 2mr9\n",
      "[WARN] removing sade_de_remc from 1wqc\n",
      "[WARN] removing sade_mc from 1wqc\n",
      "[WARN] removing sade_de_mc from 1wqc\n",
      "[WARN] removing sade_de_remc from 1acw\n",
      "[WARN] removing sade_mc from 1acw\n",
      "[WARN] removing sade_de_mc from 1acw\n",
      "[WARN] removing sade_de_remc from 1utg\n",
      "[WARN] removing sade_mc from 1utg\n",
      "[WARN] removing sade_de_mc from 1utg\n",
      "[WARN] removing sade_de_remc from 1l2y\n",
      "[WARN] removing sade_mc from 1l2y\n",
      "[WARN] removing sade_de_mc from 1l2y\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "def list_contains_substring(container, string):\n",
    "    return any(map(lambda x: x in string, container))\n",
    "\n",
    "\n",
    "def find_experiment_folder(run):\n",
    "    dirs = [f for f in os.listdir() if os.path.isdir(f)]\n",
    "    exp_folder = [f for f in dirs if list_contains_substring(runs, f)]\n",
    "    \n",
    "    if len(exp_folder) > 1:\n",
    "        raise Exception('Found more than one experiment folder. Aborting\\n%s' % exp_folder)\n",
    "        \n",
    "    return exp_folder[0]\n",
    "\n",
    "\n",
    "def load_repack_data():\n",
    "    os.chdir('repack')\n",
    "    d = utils.get_by_best_rmsd()\n",
    "    os.chdir('..')\n",
    "    \n",
    "    return d\n",
    "\n",
    "\n",
    "def get_best_by_score_3(data):\n",
    "    pass\n",
    "\n",
    "\n",
    "def load_full_repack_data(data):\n",
    "    os.chdir('repack')\n",
    "    \n",
    "    d = {}\n",
    "    d['best_by_rmsd'] = utils.get_by_best_rmsd()\n",
    "    d['best_by_energy'] = utils.get_by_best_energy()\n",
    "    d['best_by_score3'] = get_best_by_score_3(data)\n",
    "    d['all_repacks'] = utils.extract_all_repack_data()\n",
    "    \n",
    "    os.chdir('..')\n",
    "    \n",
    "    return d\n",
    "\n",
    "\n",
    "def load_hooke_jeeves_data():\n",
    "    os.chdir('hooke-jeeves')\n",
    "    d = []\n",
    "    wanted_data = ['hooke_time', 'spent_evals']\n",
    "    \n",
    "    for datafile in os.listdir():\n",
    "        with open(datafile, 'rt') as f:\n",
    "            new_data = {}\n",
    "            for line in f.readlines():\n",
    "                tokens = re.sub(' {2,}', ' ', line.strip()).split(' ')\n",
    "\n",
    "                has_data = any([wanted == tokens[0][:-1] for wanted in wanted_data])\n",
    "                if has_data:\n",
    "                    new_data[tokens[0][:-1]] = float(tokens[1])\n",
    "                    \n",
    "            d.append(new_data)\n",
    "            \n",
    "    os.chdir('..')\n",
    "    \n",
    "    return d\n",
    "\n",
    "\n",
    "def load_stats_data():\n",
    "    os.chdir('stats')\n",
    "    d = []\n",
    "    \n",
    "    for datafile in os.listdir():\n",
    "        with open(datafile, 'rt') as f:\n",
    "            new_data = {}\n",
    "            for line in f.readlines():\n",
    "                tokens = re.sub(' {2,}', ' ', line.strip()).split(' ')\n",
    "\n",
    "                new_data['evals'] = float(tokens[0])\n",
    "                new_data['time'] = float(tokens[8])\n",
    "                    \n",
    "            d.append(new_data)\n",
    "            \n",
    "    os.chdir('..')\n",
    "    \n",
    "    return d\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    reset_path()\n",
    "    \n",
    "    data = {}\n",
    "    data_full = {}\n",
    "    data_hooke = {}\n",
    "    data_stats = {}\n",
    "    \n",
    "    for run in runs:\n",
    "        os.chdir(run)\n",
    "        \n",
    "        exp_folder = find_experiment_folder(run)\n",
    "        os.chdir(exp_folder)\n",
    "        \n",
    "        protein_folders = [f for f in os.listdir() if len(f) == 4 and os.path.isdir(f)]\n",
    "        \n",
    "        for pf in protein_folders:\n",
    "            if pf in protein_blacklist:\n",
    "                continue\n",
    "                \n",
    "            os.chdir(pf)\n",
    "            if pf not in data.keys():\n",
    "                data[pf] = {}\n",
    "                data_full[pf] = {}\n",
    "                data_hooke[pf] = {}\n",
    "                data_stats[pf] = {}\n",
    "            \n",
    "            for exp in os.listdir():\n",
    "                os.chdir(exp)\n",
    "                    \n",
    "                data[pf][exp] = load_repack_data()\n",
    "                data_full[pf][exp] = load_full_repack_data(data)\n",
    "                data_hooke[pf][exp] = load_hooke_jeeves_data()\n",
    "                data_stats[pf][exp] = load_stats_data()\n",
    "                \n",
    "                os.chdir('..')\n",
    "            \n",
    "            os.chdir('..')\n",
    "        \n",
    "        os.chdir('..')\n",
    "        os.chdir('..')\n",
    "        \n",
    "    remove_not_common_methods(data)\n",
    "    remove_not_common_methods(data_full)\n",
    "    remove_not_common_methods(data_hooke)\n",
    "    remove_not_common_methods(data_stats)\n",
    "        \n",
    "    return data, data_full, data_hooke, data_stats\n",
    "    \n",
    "    \n",
    "data, data_full, data_hooke, data_stats = load_data()\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric(data, protein, experiment, metric):\n",
    "    data_source = data[protein][experiment]\n",
    "    data_metric = [d[metric] for d in data_source]\n",
    "    \n",
    "    return data_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1acw & $-0.1656$ & $0.3372$ & $0.2616$ & $0.4944$ & $0.2589$ & $0.5765$ \\\\ \\hline\n",
      "1ail & $-0.1113$ & $0.4629$ & $0.2470$ & $0.7731$ & $0.2379$ & $0.7278$ \\\\ \\hline\n",
      "1crn & $-0.0620$ & $0.4203$ & $-0.0297$ & $0.5865$ & $-0.1128$ & $0.4368$ \\\\ \\hline\n",
      "1enh & $-0.0558$ & $0.4854$ & $-0.1277$ & $0.5577$ & $-0.1380$ & $0.6081$ \\\\ \\hline\n",
      "1l2y & $0.2505$ & $0.3773$ & $0.3856$ & $0.5036$ & $0.6653$ & $0.7176$ \\\\ \\hline\n",
      "1rop & $0.8336$ & $0.4484$ & $0.7814$ & $0.9170$ & $1.2214$ & $1.3530$ \\\\ \\hline\n",
      "1utg & $-0.3506$ & $0.4712$ & $0.1346$ & $0.5762$ & $0.1793$ & $0.7202$ \\\\ \\hline\n",
      "1wqc & $-0.2543$ & $0.4381$ & $0.1729$ & $0.5624$ & $0.2160$ & $0.6377$ \\\\ \\hline\n",
      "1zdd & $0.2283$ & $0.4144$ & $0.7429$ & $0.6098$ & $0.7470$ & $0.9897$ \\\\ \\hline\n",
      "2mr9 & $-0.2667$ & $0.6094$ & $0.2190$ & $0.5679$ & $0.1875$ & $0.6957$ \\\\ \\hline\n"
     ]
    }
   ],
   "source": [
    "def custom_metric_table(wanted_experiments=['classic-abinitio', 'sade_mc_final', 'sade_remc_final']):\n",
    "    for protein in sorted(list(data.keys())):\n",
    "        if protein in protein_blacklist:\n",
    "            continue\n",
    "                \n",
    "        to_print = ['%s' % protein]\n",
    "        for experiment in wanted_experiments:\n",
    "            if experiment not in wanted_experiments:\n",
    "                continue\n",
    "                                \n",
    "            rmsd_before = get_metric(data, protein, experiment, 'rmsd_before')\n",
    "            rmsd_after = get_metric(data, protein, experiment, 'rmsd_after')\n",
    "            \n",
    "            diff = map(\n",
    "                lambda x: x[0] - x[1],\n",
    "                zip(rmsd_before, rmsd_after)\n",
    "            )\n",
    "            \n",
    "            diff = list(diff)\n",
    "            \n",
    "            to_print.append(\"$%0.4f$ & $%0.4f$\" % (np.mean(diff), np.std(diff)))\n",
    "        \n",
    "        print(' & '.join(to_print), end='')\n",
    "        print(' \\\\\\\\ \\\\hline')\n",
    "    \n",
    "custom_metric_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\centering\n",
      "\\begin{tabular}{r|r|r|r}\n",
      "Protein & Wins & Loses & Draws \\\\ \\hline \\hline\n",
      " 1acw &  2 &  0 &  0 \\\\ \\hline\n",
      " 1ail &  0 &  0 &  2 \\\\ \\hline\n",
      " 1crn &  1 &  1 &  0 \\\\ \\hline\n",
      " 1enh &  1 &  0 &  1 \\\\ \\hline\n",
      " 1l2y &  2 &  0 &  0 \\\\ \\hline\n",
      " 1rop &  2 &  0 &  0 \\\\ \\hline\n",
      " 1utg &  2 &  0 &  0 \\\\ \\hline\n",
      " 1wqc &  2 &  0 &  0 \\\\ \\hline\n",
      " 1zdd &  2 &  0 &  0 \\\\ \\hline\n",
      " 2mr9 &  2 &  0 &  0 \\\\ \\hline\n",
      "\\end{tabular}\n",
      "\\caption{Summary of Mann-Whitney \\texttt{best-by-energy} using score3}\n",
      "\\label{tab:mann-whitney-summary-best-by-energy-score3}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "def apply_mann_whitney(data, method_a, method_b, protein):\n",
    "    data_a = data[method_a]['data']['raw']\n",
    "    data_b = data[method_b]['data']['raw']\n",
    "    _, p = scipy.stats.mannwhitneyu(data_a, data_b)\n",
    "    \n",
    "    mean_a = data[method_a]['data']['mean']\n",
    "    mean_b = data[method_b]['data']['mean']\n",
    "    \n",
    "    return p, mean_a, mean_b\n",
    "\n",
    "\n",
    "def mann_whitney_summary(alpha=0.05, mode='best_by_energy', metric='score', ref=[], ignore=[], skip_all_ref=False):\n",
    "    summary = data_utils.experiment_summary(alldata, mode=mode, metric=metric, with_raw=True)\n",
    "    proteins = sorted(summary.keys())\n",
    "    \n",
    "    methods = sorted(summary[proteins[0]].keys())\n",
    "    \n",
    "    proposed_wins = 0\n",
    "    proposed_loses = 0\n",
    "    proposed_draws = 0\n",
    "    \n",
    "    print('\\\\begin{table}')\n",
    "    print('\\\\centering')\n",
    "    column_header = '\\\\begin{tabular}{r|r|r|r}'\n",
    "    print(column_header)\n",
    "        \n",
    "    print('%s \\\\\\\\ \\\\hline \\\\hline' % ('Protein & Wins & Loses & Draws'))\n",
    "    \n",
    "    done = set()\n",
    "    \n",
    "    for protein in proteins:\n",
    "        proposed_wins = 0\n",
    "        proposed_loses = 0\n",
    "        proposed_draws = 0\n",
    "        for i in range(len(methods)):\n",
    "            method_a = methods[i]\n",
    "            if all(map(lambda x: method_a != x, ref)):\n",
    "                continue\n",
    "                \n",
    "            for j in range(len(methods)):\n",
    "                method_b = methods[j]\n",
    "                \n",
    "                key = ','.join(sorted([protein, method_a, method_b]))\n",
    "                \n",
    "                if key in done:\n",
    "                    continue\n",
    "                \n",
    "                done.add(key)\n",
    "                \n",
    "                if any(map(lambda x: method_a == x or method_b == x, ignore)):\n",
    "                    continue\n",
    "                    \n",
    "                if skip_all_ref:\n",
    "                    method_a_match = any(map(lambda x: method_a == x, ref))\n",
    "                    method_b_match = any(map(lambda x: method_b == x, ref))\n",
    "                    \n",
    "                    if method_a_match and method_b_match:\n",
    "                        continue\n",
    "                                    \n",
    "                p, mean_a, mean_b = apply_mann_whitney(summary[protein], method_a, method_b, protein)\n",
    "                \n",
    "                if p > alpha:\n",
    "                    proposed_draws += 1\n",
    "#                     print('%5s %20s %20s %f  [DRAW]' % (protein, method_a, method_b, p))\n",
    "                    continue\n",
    "                    \n",
    "                if mean_a < mean_b:\n",
    "                    proposed_wins += 1\n",
    "#                     print('%5s %20s %20s %f' % (protein, method_a, method_b, p))\n",
    "                else:\n",
    "                    proposed_loses += 1\n",
    "#                     print('%5s %20s %20s %f' % (protein, method_b, method_a, p))\n",
    "        \n",
    "#         print('%5s  wins: %2s  loses %2d  draws: %2d' % (protein, proposed_wins, proposed_loses, proposed_draws))\n",
    "        print('%5s & %2s & %2d & %2d \\\\\\\\ \\\\hline' % (protein, proposed_wins, proposed_loses, proposed_draws))\n",
    "    \n",
    "    print('\\\\end{tabular}')\n",
    "    metric_dict = { 'scorefxn': 'scorefxn', 'rmsd_after': 'RMSD', 'score': 'score3' }\n",
    "    metric_string = metric_dict[metric]\n",
    "    print('\\\\caption{Summary of Mann-Whitney \\\\texttt{%s} using %s}' % (mode.replace('_', '-'), metric_string))\n",
    "    print('\\\\label{tab:mann-whitney-summary-%s-%s}' % (mode.replace('_', '-'), metric_string))\n",
    "    print('\\\\end{table}')\n",
    "\n",
    "alldata = data_full\n",
    "    \n",
    "mann_whitney_summary(\n",
    "    alpha=0.05,\n",
    "    mode='best_by_energy',\n",
    "    metric='score',\n",
    "    ref=['sade_mc_final', 'sade_remc_final'],\n",
    "    ignore=['sade_remc', 'sade_remc_ffi9_02', 'sade_mc_ffi9_02'],\n",
    "    skip_all_ref=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kruskal_wallis_table(alpha=0.05, mode='best_by_rmsd', metric='rmsd_after'):\n",
    "    summary = data_utils.experiment_summary(alldata, mode=mode, metric=metric, with_raw=True)\n",
    "    proteins = sorted(summary.keys())\n",
    "    methods = sorted(summary[proteins[0]].keys())\n",
    "    \n",
    "    print('\\\\begin{table}')\n",
    "    print('\\\\centering')\n",
    "    print('\\\\begin{tabular}{r|c}')\n",
    "\n",
    "    methods_header = 'Protein & $p$-value'\n",
    "    \n",
    "    print('%s \\\\\\\\ \\\\hline \\\\hline' % (methods_header))\n",
    "    \n",
    "    for protein in proteins:         \n",
    "        print('%s & ' % protein, end='')\n",
    "        \n",
    "        data = [\n",
    "            summary[protein][method]['data']['raw'] for method in methods\n",
    "        ]\n",
    "            \n",
    "        stats, p = scipy.stats.kruskal(*data)\n",
    "        \n",
    "        if p < alpha:\n",
    "            print('$\\\\bm{%4.4f}$' % p, end='')\n",
    "        else:\n",
    "            print('    $%4.4f$ ' % p, end='')\n",
    "            \n",
    "        print(' \\\\\\\\ \\\\hline')   \n",
    "            \n",
    "    print('\\\\end{tabular}')\n",
    "    metric_dict = { 'scorefxn': 'scorefxn', 'rmsd_after': 'RMSD', 'score': 'score3' }\n",
    "    metric_string = metric_dict[metric]\n",
    "    print('\\\\caption{Kruskal-Wallis for \\\\texttt{%s} using %s}' % (mode.replace('_', '-'), metric_string))\n",
    "    print('\\\\label{tab:kruskal-wallis-wilk-%s-%s}' % (mode.replace('_', '-'), metric_string))\n",
    "    print('\\\\end{table}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\centering\n",
      "\\begin{tabular}{r|c}\n",
      "Protein & $p$-value \\\\ \\hline \\hline\n",
      "1acw & $\\bm{0.0000}$ \\\\ \\hline\n",
      "1ail & $\\bm{0.0000}$ \\\\ \\hline\n",
      "1crn & $\\bm{0.0000}$ \\\\ \\hline\n",
      "1enh & $\\bm{0.0000}$ \\\\ \\hline\n",
      "1l2y & $\\bm{0.0000}$ \\\\ \\hline\n",
      "1rop & $\\bm{0.0000}$ \\\\ \\hline\n",
      "1utg & $\\bm{0.0000}$ \\\\ \\hline\n",
      "1wqc & $\\bm{0.0000}$ \\\\ \\hline\n",
      "1zdd & $\\bm{0.0000}$ \\\\ \\hline\n",
      "2mr9 & $\\bm{0.0000}$ \\\\ \\hline\n",
      "\\end{tabular}\n",
      "\\caption{Kruskal-Wallis for \\texttt{best-by-energy} using score3}\n",
      "\\label{tab:kruskal-wallis-wilk-best-by-energy-score3}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "kruskal_wallis_table(alpha=0.05, mode='best_by_energy', metric='score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
